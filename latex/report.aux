\relax 
\citation{attn_is_all}
\citation{dao2022flashattentionfastmemoryefficientexact}
\citation{rabe2022selfattentiondoesneedon2,liu2023blockwiseparalleltransformerlarge}
\citation{liu2023ringattentionblockwisetransformers}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-A}}Background and Motivation}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-B}}Problem Statement}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {I-C}}Objectives and Scope}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {II}Literature Review}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Review of Relevant Literature}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Identification of Gaps in Existing Research}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Model Selection}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Optimization Procedure}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Token distribution across GPUs under different partitioning strategies. As heterogeneity increases (lower MPS), adaptive strategies assign more tokens to the faster GPU to balance execution time.}}{2}{}\protected@file@percent }
\newlabel{fig:token_dist}{{1}{2}{}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Profiling Tools and Methods}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Matrix multiplication latency as a function of matrix size under different MPS throttling levels. Lower MPS percentages result in proportionally higher latency for compute-bound operations.}}{2}{}\protected@file@percent }
\newlabel{fig:matmul_latency}{{2}{2}{}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Normalized performance scaling with MPS percentage. Performance scales approximately linearly with MPS allocation, enabling predictable modeling of heterogeneous configurations.}}{3}{}\protected@file@percent }
\newlabel{fig:perf_scaling}{{3}{3}{}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Polynomial regression surface for performance prediction. The model captures the joint dependence on sequence length and MPS percentage with $R^2 = 0.922$.}}{3}{}\protected@file@percent }
\newlabel{fig:regression}{{4}{3}{}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Evaluation Metrics}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experimental Results}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Experimental Setup}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Performance Comparison}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Discussion}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Interpretation of Results}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Slowdown factor for each partitioning strategy across sequence lengths and MPS configurations. Lower values indicate better performance. The dashed red line at 1.0 represents ideal (homogeneous) performance. Asterisks mark the best-performing strategy for each configuration.}}{4}{}\protected@file@percent }
\newlabel{fig:strategy_eval}{{5}{4}{}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Speedup of uneven split over even split. Darker green indicates larger improvements. The greatest benefits occur at high heterogeneity (low MPS) and long sequences.}}{4}{}\protected@file@percent }
\newlabel{fig:heatmap}{{6}{4}{}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Absolute latency at 10\% MPS (extreme heterogeneity). Adaptive strategies reduce latency by up to 4.4x compared to even split.}}{4}{}\protected@file@percent }
\newlabel{fig:extreme}{{7}{4}{}{figure.7}{}}
\bibstyle{IEEEtran}
\bibdata{ref}
\bibcite{attn_is_all}{1}
\bibcite{dao2022flashattentionfastmemoryefficientexact}{2}
\bibcite{rabe2022selfattentiondoesneedon2}{3}
\bibcite{liu2023blockwiseparalleltransformerlarge}{4}
\bibcite{liu2023ringattentionblockwisetransformers}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Efficiency relative to homogeneous baseline. Adaptive strategies maintain substantially higher efficiency as heterogeneity increases.}}{5}{}\protected@file@percent }
\newlabel{fig:efficiency}{{8}{5}{}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Comparison with Previous Studies}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Challenges and Limitations}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}Future Directions}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-A}}Summary of Findings}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-B}}Contributions}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-C}}Recommendations for Future Research}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{5}{}\protected@file@percent }
\gdef \@abspage@last{5}
